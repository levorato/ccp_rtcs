{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process CCP simulation results - UTC Microgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_from_collab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "import matplotlib.style as style\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import BoxStyle\n",
    "from sys import platform\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom python file from github repo: https://changhsinlee.com/colab-import-python/\n",
    "if run_from_collab:\n",
    "    !pip install requests\n",
    "    import requests\n",
    "    # Save python as file to colab working directory\n",
    "    # If you are using GitHub, make sure you get the \"Raw\" version of the code\n",
    "    url = 'https://raw.githubusercontent.com/levorato/ccp_rtcs/master/notebooks/rccp_utils.py'\n",
    "    r = requests.get(url)\n",
    "    # make sure your filename is the same as how you want to import \n",
    "    with open('rccp_utils.py', 'w') as f:\n",
    "        f.write(r.text)\n",
    "    # now we can import\n",
    "    from rccp_utils import *\n",
    "else:\n",
    "    from rccp_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Process result files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Setup project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdrive_folder= ..\n"
     ]
    }
   ],
   "source": [
    "if run_from_collab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive/')\n",
    "    gdrive_folder = '/content/gdrive/MyDrive'\n",
    "else:\n",
    "    gdrive_folder = '..'\n",
    "print('gdrive_folder=', gdrive_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Project folder is ..\n",
      "*** Instances folder is ..\\instances\n",
      "*** Output folder is ..\\rccp_experiments\n"
     ]
    }
   ],
   "source": [
    "project_folder = '..'\n",
    "antoine_instances_folder = os.path.join(project_folder, \"instances\", \"utc_skew\")\n",
    "toy_instances_folder = os.path.join(project_folder, \"instances\", \"toy\")\n",
    "instances_folder = os.path.join(project_folder, \"instances\")\n",
    "japan_instances_folder = os.path.join(project_folder, \"instances\", \"japan_microgrid\")\n",
    "output_folder = os.path.join(project_folder, \"rccp_experiments\")\n",
    "print(\"*** Project folder is\", project_folder)\n",
    "print(\"*** Instances folder is\",  instances_folder)\n",
    "print(\"*** Output folder is\", output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. List which experiments to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = [\"run_sim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\rccp_experiments\\\\run_sim']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_folder_list = [os.path.join(output_folder, exp) for exp in experiment_list]\n",
    "experiment_folder_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. List which CPP models to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_model_list = [\"robust-budget\", \"robust-box\", \"robust-budget\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Select instance_group to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_group_list = [\"utc-skew\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Select RTCS forecast types to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_type_list = [\"average\"]  # average-based RTCS forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing,  antoine-skew  instances...\n",
      "# instances to process:  9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('..\\\\instances\\\\utc_skew\\\\A_instance2_1000s_skewed-left.txt',\n",
       "  '..\\\\instances\\\\utc_skew\\\\..\\\\instances\\\\utc_skew\\\\A_instance2_1000s_skewed-left.txt'),\n",
       " ('..\\\\instances\\\\utc_skew\\\\A_instance2_1000s_skewed-right.txt',\n",
       "  '..\\\\instances\\\\utc_skew\\\\..\\\\instances\\\\utc_skew\\\\A_instance2_1000s_skewed-right.txt'),\n",
       " ('..\\\\instances\\\\utc_skew\\\\A_instance2_1000s_uniform.txt',\n",
       "  '..\\\\instances\\\\utc_skew\\\\..\\\\instances\\\\utc_skew\\\\A_instance2_1000s_uniform.txt'),\n",
       " ('..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Cons_1000s_skewed-left.txt',\n",
       "  '..\\\\instances\\\\utc_skew\\\\..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Cons_1000s_skewed-left.txt'),\n",
       " ('..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Cons_1000s_skewed-right.txt',\n",
       "  '..\\\\instances\\\\utc_skew\\\\..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Cons_1000s_skewed-right.txt'),\n",
       " ('..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Cons_1000s_uniform.txt',\n",
       "  '..\\\\instances\\\\utc_skew\\\\..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Cons_1000s_uniform.txt'),\n",
       " ('..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Prod_1000s_skewed-left.txt',\n",
       "  '..\\\\instances\\\\utc_skew\\\\..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Prod_1000s_skewed-left.txt'),\n",
       " ('..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Prod_1000s_skewed-right.txt',\n",
       "  '..\\\\instances\\\\utc_skew\\\\..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Prod_1000s_skewed-right.txt'),\n",
       " ('..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Prod_1000s_uniform.txt',\n",
       "  '..\\\\instances\\\\utc_skew\\\\..\\\\instances\\\\utc_skew\\\\A_instance2_1NDU_Prod_1000s_uniform.txt')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instances_to_process = [\"A_instance2_1000s_skewed-left.txt\", \"A_instance2_1000s_skewed-right.txt\", \"A_instance2_1000s_uniform.txt\"]\n",
    "instance_group = \"antoine-skew\"\n",
    "instances_to_process = get_instance_list(project_folder, antoine_instances_folder, toy_instances_folder, \n",
    "                                         japan_instances_folder, instance_group)\n",
    "instances_to_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Read consolidated result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_list = []\n",
    "result_path = os.path.join(experiment_folder_list[0], \"run_sim_utc_forecast_avg.results.pkl.gz\")\n",
    "df = pd.read_pickle(result_path)\n",
    "#for instance_path in instances_to_process:\n",
    "#    instance_name = instance_path[1][instance_path[1].rfind(os.path.sep)+1:]\n",
    "#    result_path = os.path.join(experiment_folder_list[0], \"output\", \"simulation\", \"zip\", instance_name)\n",
    "#    df_ = read_concatenated_trace_df(result_path)\n",
    "#    df_['InstanceName'] = instance_name\n",
    "#    df_list.append(df_)\n",
    "#df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the output folders for processed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reportfolder = os.path.join(output_folder, 'consolidated_results')\n",
    "reportfolder_graph = os.path.join(reportfolder, 'graphs')\n",
    "reportfolder_table = os.path.join(reportfolder, 'tables')\n",
    "if not os.path.exists(reportfolder_graph):\n",
    "    os.makedirs(reportfolder_graph)\n",
    "if not os.path.exists(reportfolder_table):\n",
    "    os.makedirs(reportfolder_table)\n",
    "print('Saving files on folder: ' + reportfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Tables\n",
    "\n",
    "Obtain list of Model, Strategy, ModelPolicy, ForecastType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = df['Model'].unique().tolist()\n",
    "strategy_list = df['Strategy'].unique().tolist()\n",
    "model_policy_list = df['ModelPolicy'].unique().tolist()\n",
    "reoptimize_value_list = df['Reoptimize'].unique().tolist()\n",
    "forecast_type_list = df['ForecastType'].unique().tolist()\n",
    "print(\"Model\", model_list)\n",
    "print(\"Strategy\", strategy_list)\n",
    "print(\"ModelPolicy\", model_policy_list)\n",
    "print(\"Reoptimize\", reoptimize_value_list)\n",
    "print(\"ForecastType\", forecast_type_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1. Simulation performance given all instances \n",
    "\n",
    "Model-wise RTCS simulation performance comparison, given all instances.\n",
    "\n",
    "* Median, Mean, Std. dev and sum of each measure (cost, e_td, gap, time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_instance_stats = dict()\n",
    "for instance_name in instances_to_process:  # group by instance\n",
    "    df_itype = df[(df['InstanceName'] == instance_name)]\n",
    "    _forecast_type_list = df_itype['ForecastType'].unique().tolist()\n",
    "    for forecast_type in _forecast_type_list:\n",
    "        df_forecast = df_itype[df_itype['ForecastType'] == forecast_type]\n",
    "        _model_list = df_forecast['Model'].unique().tolist()\n",
    "        for model in _model_list:\n",
    "            df_model = df_forecast[df_forecast['Model'] == model]\n",
    "            _gamma_perc_list = df_model['GammaPerc'].unique().tolist()\n",
    "            for gamma_perc in _gamma_perc_list:\n",
    "                df_gamma = df_model[df_model['GammaPerc'] == gamma_perc]\n",
    "                _strategy_list = df_gamma['Strategy'].unique().tolist()\n",
    "                for strategy in _strategy_list:\n",
    "                    df_strategy = df_gamma[df_gamma['Strategy'] == strategy]\n",
    "                    _model_policy_list = df_strategy['ModelPolicy'].unique().tolist()\n",
    "                    for model_policy in _model_policy_list:\n",
    "                        df_policy = df_strategy[df_strategy['ModelPolicy'] == model_policy]\n",
    "                        _reoptimize_value_list = df_policy['Reoptimize'].unique().tolist()\n",
    "                        for reopt in _reoptimize_value_list:\n",
    "                            df_reopt = df_policy[df_policy['Reoptimize'] == reopt]\n",
    "                            _scenario_list = df_reopt['ScenarioId'].unique().tolist()\n",
    "                            for scenario in _scenario_list:\n",
    "                                df_ = df_reopt[df_reopt['ScenarioId'] == scenario]\n",
    "                                key = (instance_name, forecast_type, model, gamma_perc, strategy, model_policy, reopt, scenario)\n",
    "                                per_instance_stats[key] = dict()\n",
    "                                #per_instance_stats[key]['% Best Performance'] = calculate_perc_best_performance(df_instance, model)\n",
    "                                #per_instance_stats[key]['% Solved'] = calculate_perc_solved(df_rpfs, model, instance_type, instance_size)\n",
    "                                #per_instance_stats[key]['Avg. % gap'] = calculate_avg_perc_gap(df_instance, model)\n",
    "                                per_instance_stats[key]['Median time'] = np.round(df_['RealProcTime'].median(), 2)\n",
    "                                per_instance_stats[key]['Avg. time'] = np.round(df_['RealProcTime'].mean(), 2)\n",
    "                                per_instance_stats[key]['Std. dev. of time'] = np.round(df_['RealProcTime'].std(), 2)\n",
    "                                per_instance_stats[key]['Total time'] = np.round(df_['RealProcTime'].sum(), 2)\n",
    "                                \n",
    "                                per_instance_stats[key]['Median cost'] = np.round(df_['cost'].median(), 2)\n",
    "                                per_instance_stats[key]['Avg. cost'] = np.round(df_['cost'].mean(), 2)\n",
    "                                per_instance_stats[key]['Std. dev. of cost'] = np.round(df_['cost'].std(), 2)\n",
    "                                per_instance_stats[key]['Total cost'] = np.round(df_['cost'].sum(), 2)\n",
    "                                \n",
    "                                per_instance_stats[key]['Median gap'] = np.round(df_['gap'].median(), 2)\n",
    "                                per_instance_stats[key]['Avg. gap'] = np.round(df_['gap'].mean(), 2)\n",
    "                                per_instance_stats[key]['Std. dev. of gap'] = np.round(df_['gap'].std(), 2)\n",
    "                                per_instance_stats[key]['Total gap'] = np.round(df_['gap'].sum(), 2)\n",
    "                                \n",
    "                                per_instance_stats[key]['Median e_td'] = np.round(df_['e_td'].median(), 2)\n",
    "                                per_instance_stats[key]['Avg. e_td'] = np.round(df_['e_td'].mean(), 2)\n",
    "                                per_instance_stats[key]['Std. dev. of e_td'] = np.round(df_['e_td'].std(), 2)\n",
    "                                per_instance_stats[key]['Total e_td'] = np.round(df_['e_td'].sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table1 = pd.DataFrame.from_dict(per_instance_stats)\n",
    "df_table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1. Total cost of each simulation, grouped by CCP model and simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['t', 'd', 'OptTimeSpent']).groupby(by=['InstanceName', 'Model', 'GammaPerc', 'Strategy', 'ModelPolicy', 'Reoptimize', 'ForecastType']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2. Cost of the most expensive scenario (worst simulation cost), grouped by CCP model and simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['t', 'd', 'OptTimeSpent', 'ObjValue']).groupby(by=['InstanceName', 'Model', 'GammaPerc', 'Strategy', 'ModelPolicy', 'Reoptimize', 'ForecastType', 'ScenarioId']).sum().\\\n",
    "    groupby(by=['InstanceName', 'Model', 'GammaPerc', 'Strategy', 'ModelPolicy', 'Reoptimize', 'ForecastType']).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3. RTCS performance map (robust wins)\n",
    "\n",
    "Number of scenarios where Robust RTCS obtained smaller cost, when compared to the Deterministic RTCS, when simulating the same scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df.drop(columns=['t', 'd', 'OptTimeSpent', 'ObjValue']).groupby(by=['InstanceName', 'Model', 'GammaPerc', 'Strategy', 'ModelPolicy', 'Reoptimize', 'ForecastType', 'ScenarioId']).sum()\\\n",
    "    .drop(columns=['gap', 'RealProcTime'])\n",
    "df_rob = df_group.reset_index()\n",
    "df_rob = df_rob[(df_rob['Model'] == 'robust-budget') | (df_rob['Model'] == 'robust-box')]\n",
    "df_det = df_group.reset_index()\n",
    "df_det = df_det[df_det['Model'] == 'deterministic']\n",
    "#df_rob\n",
    "df_wins = df_rob.merge(df_det, on=['InstanceName', 'Strategy', 'ModelPolicy', 'Reoptimize', 'ForecastType', 'ScenarioId'], suffixes=('_rob', '_det'))\\\n",
    "    .drop(columns=['Model_det', 'Gamma_rob', 'Gamma_det', 'GammaPerc_det'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins['rob_wins'] = (df_wins['cost_rob'] < df_wins['cost_det']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.groupby(by=['InstanceName', 'Model_rob', 'GammaPerc_rob', 'Strategy', 'ModelPolicy', 'Reoptimize', 'ForecastType']).sum().drop(columns=['ScenarioId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4. Cheapest RTCS Strategy, per instance and model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df.drop(columns=['t', 'd', 'OptTimeSpent', 'ObjValue']).groupby(by=['InstanceName', 'Model', 'GammaPerc', 'Strategy', 'ModelPolicy', 'Reoptimize', 'ForecastType', 'ScenarioId']).sum()\\\n",
    "    .drop(columns=['gap', 'RealProcTime'])\n",
    "# Find the cheapest strategy for each model type\n",
    "df_cheapest = df_group.groupby(by=['InstanceName', 'Model', 'GammaPerc', 'ScenarioId']).min().drop(columns=['e_td'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rob = df_cheapest.reset_index()\n",
    "df_rob = df_rob[(df_rob['Model'] == 'robust-budget') | (df_rob['Model'] == 'robust-box')]\n",
    "df_det = df_cheapest.reset_index()\n",
    "df_det = df_det[df_det['Model'] == 'deterministic']\n",
    "df_wins = df_rob.merge(df_det, on=['InstanceName', 'ScenarioId'], suffixes=('_rob', '_det'))\\\n",
    "    .drop(columns=['Model_det', 'Gamma_rob', 'Gamma_det', 'GammaPerc_det'])\n",
    "df_wins['rob_wins'] = (df_wins['cost_rob'] <= df_wins['cost_det']).astype(int)\n",
    "df_wins['det_wins'] = (df_wins['cost_rob'] > df_wins['cost_det']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.groupby(by=['InstanceName', 'Model_rob', 'GammaPerc_rob']).sum().drop(columns=['ScenarioId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Fazer um kde distribution plot dos custos do RTCS obtidos nas simulacoes: robusto-gamma vs. deterministico\n",
    "\n",
    "### TODO Fazer uma tabela com as medidas estatisticas (para cada distribuicao usada) de cada simulacao, incluindo valor esperado, SD, percentis 95, 99 e valor maximo observado empiricamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_folder in experiment_folder_list:\n",
    "    for instance_group in instance_group_list:\n",
    "        instance_list = get_instance_list(project_folder, antoine_instances_folder, toy_instances_folder, instance_group)\n",
    "        print(instance_group, instance_list)\n",
    "        for model in simulated_model_list:\n",
    "            for forecast_type in forecast_type_list:\n",
    "                print(model, forecast_type)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "        result_path = create_full_dir(normpath(experiment_folder), [\"output\", \"simulation\", \"zip\", instance_name])\n",
    "        scenario_subpath = create_trace_scenario_filename(\n",
    "            model, Gamma_perc, test_name, instance_name, sim_strategy, model_policy, reoptimize, scenario_id)\n",
    "        result_file_base = joinpath(normpath(result_path), scenario_subpath)\n",
    "        output_file_trace_arrow = result_file_base * \".arrow\"\n",
    "        output_file_var_arrow = result_file_base * \"_var.arrow\"\n",
    "    \n",
    "        result_file_zip = result_file_base * \".zip\"\n",
    "        move_files_to_zip_archive(output_file_zip, [output_file_log, output_file_df, output_file_var_arrow, output_file_trace_arrow], general_logger)\n",
    "        trace_df = Arrow.read(output_file_trace_arrow; compress=:lz4)\n",
    "        var_df = Arrow.read(output_file_var_arrow; compress=:lz4)\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
