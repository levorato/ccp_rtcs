{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process CCP simulation results - Japan Microgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_from_collab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "import matplotlib.style as style\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import BoxStyle\n",
    "from sys import platform\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom python file from github repo: https://changhsinlee.com/colab-import-python/\n",
    "if run_from_collab:\n",
    "    !pip install requests\n",
    "    import requests\n",
    "    # Save python as file to colab working directory\n",
    "    # If you are using GitHub, make sure you get the \"Raw\" version of the code\n",
    "    url = 'https://raw.githubusercontent.com/levorato/ccp_rtcs/master/notebooks/rccp_utils.py'\n",
    "    r = requests.get(url)\n",
    "    # make sure your filename is the same as how you want to import \n",
    "    with open('rccp_utils.py', 'w') as f:\n",
    "        f.write(r.text)\n",
    "    # now we can import\n",
    "    from rccp_utils import *\n",
    "else:\n",
    "    from rccp_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Process result files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Setup project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_from_collab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive/')\n",
    "    gdrive_folder = '/content/gdrive/MyDrive'\n",
    "else:\n",
    "    gdrive_folder = '../..'\n",
    "print('gdrive_folder=', gdrive_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = '../../doutorado/robusto/RCCP'\n",
    "antoine_instances_folder = os.path.join(project_folder, \"instances\", \"utc_skew\")\n",
    "toy_instances_folder = os.path.join(project_folder, \"instances\", \"toy\")\n",
    "instances_folder = os.path.join(project_folder, \"instances\")\n",
    "japan_instances_folder = os.path.join(project_folder, \"instances\", \"japan_microgrid\")\n",
    "output_folder = os.path.join(gdrive_folder, \"rccp_experiments\")\n",
    "results_folder = os.path.join(gdrive_folder, \"rccp_results\")\n",
    "reportfolder = results_folder\n",
    "cost_results_folder = os.path.join(output_folder, 'consolidated_results', 'df')\n",
    "var_results_folder = os.path.join(output_folder, 'consolidated_results', 'df')\n",
    "print(\"*** Project folder is\", project_folder)\n",
    "print(\"*** Instances folder is\",  instances_folder)\n",
    "print(\"*** Output folder is\", output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reportfolder = os.path.join(output_folder, 'consolidated_results')\n",
    "reportfolder_graph = os.path.join(reportfolder, 'graphs')\n",
    "reportfolder_table = os.path.join(reportfolder, 'tables')\n",
    "if not os.path.exists(reportfolder_graph):\n",
    "    os.makedirs(reportfolder_graph)\n",
    "if not os.path.exists(reportfolder_table):\n",
    "    os.makedirs(reportfolder_table)\n",
    "print('Saving files on folder: ' + reportfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. List which experiments to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = [\"run_sim_japan_forecast_avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder_list = [os.path.join(output_folder, exp) for exp in experiment_list]\n",
    "experiment_folder_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. List which CPP models to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_model_list = [\"robust-budget\", \"robust-box\", \"robust-budget\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Select instance_group to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_group_list = [\"japan-10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Select RTCS forecast types to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_type_list = [\"average\"]  # average-based RTCS forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instances_to_process = [\"A_instance2_1000s_skewed-left.txt\", \"A_instance2_1000s_skewed-right.txt\", \"A_instance2_1000s_uniform.txt\"]\n",
    "instance_group = \"japan-10\"\n",
    "instances_to_process = get_instance_list(project_folder, antoine_instances_folder, toy_instances_folder, japan_instances_folder, instance_group)\n",
    "instances_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Read consolidated result file with model solution / costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "cost_results_folder = os.path.join(output_folder, 'consolidated_results', 'df')\n",
    "print(cost_results_folder)\n",
    "for filepath in glob.glob(os.path.join(cost_results_folder, experiment_list[0] + '.*.cost-results.pkl.gz')):\n",
    "    df_ = pd.read_pickle(filepath)\n",
    "    df_list.append(df_)\n",
    "    if 'deterministic' in filepath:\n",
    "        print('Read ', filepath)\n",
    "        print(df_['GammaPerc'].unique())\n",
    "df_cost = pd.concat(df_list)\n",
    "del df_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = df_cost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip3 install pickle5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle5 as pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for file in glob.glob(os.path.join(cost_results_folder, '*deterministic*.cost-results.pkl.gz')):\n",
    "    result_path = os.path.join(experiment_folder_list[0], file)\n",
    "    with gzip.open(file,'r') as fh: \n",
    "    #with open(file, \"rb\") as fh:\n",
    "        df_ = pickle.load(fh)\n",
    "        #df_ = pd.read_pickle(data)\n",
    "        #df_['InstanceName'] = 'instance_deltamin10_' + file[file.rfind('_')+1:file.rfind('.csv.gz')]\n",
    "        df_cost = pd.concat([df_cost, df_])\n",
    "display(df_cost.info())\n",
    "display(df_cost['InstanceName'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the number of scenarios for each instance and model parameter group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df_cost[(df_cost['t'] == 1) & (df_cost['d'] == 1)].groupby(by=['InstanceName', 'Model', 'Strategy', 'Reoptimize', 'ModelPolicy', 'ForecastType', 'GammaPerc']).count()\n",
    "df_check.to_csv(os.path.join(reportfolder, 'japan-check.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cost.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cost.to_pickle(os.path.join(cost_results_folder, \n",
    "                               'run_sim_japan_forecast_avg.japan-10.instance_deltamin10-cost-results-all.pkl.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Read consolidated result files with model solution / variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for filepath in glob.glob(os.path.join(var_results_folder, experiment_list[0] + '.*.var-results.pkl.gz')):\n",
    "    with gzip.open(filepath,'r') as fh: \n",
    "        #df_ = pickle.load(fh)\n",
    "        df_ = pd.read_pickle(filepath)\n",
    "        df_list.append(df_)\n",
    "        print('Read ', filepath)\n",
    "df = pd.concat(df_list)\n",
    "del df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert g_td and h_td from array to scalar, since we heave a single battery\n",
    "df['g_td'] = [x[0] for x in df['g_td']]  # df['g_td'].astype(str).str.replace('[', '', regex=False).str.replace(']', '', regex=False).astype(float)\n",
    "df['h_td'] = [x[0] for x in df['h_td']]  # df['h_td'].astype(str).str.replace('[', '', regex=False).str.replace(']', '', regex=False).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['g_td', 'h_td']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(os.path.join(cost_results_folder, \n",
    "                               'run_sim_japan_forecast_avg.japan-10.instance_deltamin10-var-results-all.pkl.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['q_td', 'r_td'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8. Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_cost, on=['Model', 'GammaPerc', 'Gamma', 'Strategy', 'Reoptimize', 'ModelPolicy', 'ForecastType', 'ScenarioId', 't', 'd', 'InstanceName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9. Replace the InstanceName column with the season name of each instance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['OriginalInstanceName'] = df['InstanceName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InstanceName'] = df['InstanceName'].str[len('instance_deltamin10_'):-4]\n",
    "df['GammaPerc'] = df['GammaPerc'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10. Save final merged dataframe to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(os.path.join(cost_results_folder, \n",
    "                               'run_sim_japan_forecast_avg.japan-10.instance_deltamin10-all-results.pkl.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Final pre-process of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Load dataframe from disk (skips Step 1 above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(cost_results_folder, \n",
    "                               'run_sim_japan_forecast_avg.japan-10.instance_deltamin10-all-results.pkl.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Create the output folders for processed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reportfolder = os.path.join(output_folder, 'consolidated_results')\n",
    "reportfolder_graph = os.path.join(reportfolder, 'graphs')\n",
    "reportfolder_table = os.path.join(reportfolder, 'tables')\n",
    "if not os.path.exists(reportfolder_graph):\n",
    "    os.makedirs(reportfolder_graph)\n",
    "if not os.path.exists(reportfolder_table):\n",
    "    os.makedirs(reportfolder_table)\n",
    "print('Saving files on folder: ' + reportfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Obtain list of Model, Strategy, ModelPolicy, ForecastType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = df['Model'].unique().tolist()\n",
    "strategy_list = df['Strategy'].unique().tolist()\n",
    "model_policy_list = df['ModelPolicy'].unique().tolist()\n",
    "reoptimize_value_list = df['Reoptimize'].unique().tolist()\n",
    "forecast_type_list = df['ForecastType'].unique().tolist()\n",
    "instances_to_process = df['InstanceName'].unique().tolist()\n",
    "print(\"Model\", model_list)\n",
    "print(\"Strategy\", strategy_list)\n",
    "print(\"ModelPolicy\", model_policy_list)\n",
    "print(\"Reoptimize\", reoptimize_value_list)\n",
    "print(\"ForecastType\", forecast_type_list)\n",
    "print(\"InstanceName\", instances_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Create 2 new columns: one called ModelName one with the RTCS Policy\n",
    "\n",
    "* `ModelName` contains MILP model name including parameters (in the budget case)\n",
    "\n",
    "* `RTCS_Policy` concatenates the info about policy (conservative, audacious, cheapest), look-ahead (i.e., full_model, ignore_model) and model reoptimization (true, false)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelName\n",
    "df['ModelName'] = df['Model']\n",
    "df.loc[(df['Model'] == 'robust-budget'), 'ModelName'] = df.loc[(df['Model'] == 'robust-budget'), 'Model'] + '-'\\\n",
    "    + df.loc[(df['Model'] == 'robust-budget'), 'GammaPerc'].astype(str)\n",
    "df.loc[(df['Model'] == 'deterministic'), 'ModelName'] = df.loc[(df['Model'] == 'deterministic'), 'Model'] + '-'\\\n",
    "    + df.loc[(df['Model'] == 'deterministic'), 'GammaPerc'].astype(str)\n",
    "# RTCSPolicy\n",
    "df['ModelPolicy_temp'] = df['ModelPolicy']\n",
    "df.loc[(df['ModelPolicy'] == 'ignore_model'), 'ModelPolicy_temp'] = ''\n",
    "df.loc[(df['ModelPolicy'] == 'full_model'), 'ModelPolicy_temp'] = '+LA'\n",
    "df['Reoptimize_temp'] = df['Reoptimize'].astype(str)\n",
    "#df.loc[((df['Reoptimize'] == True) & (df['ModelPolicy'] == 'ignore_model')), 'Reoptimize_temp'] = '+ReOpt'  # '+ReOpt'\n",
    "df.loc[((df['Reoptimize'] == False) & (df['ModelPolicy'] == 'ignore_model')), 'Reoptimize_temp'] = ''  # '+ReOpt'\n",
    "df.loc[((df['Reoptimize'] == True) & (df['ModelPolicy'] == 'full_model')), 'Reoptimize_temp'] = '+ReOpt'  # '+ReOpt'\n",
    "df.loc[((df['Reoptimize'] == False) & (df['ModelPolicy'] == 'full_model')), 'Reoptimize_temp'] = ''  # '+ReOpt'\n",
    "\n",
    "df['RTCS_Policy'] = df['Strategy'] + df['ModelPolicy_temp'] + df['Reoptimize_temp']\n",
    "df.drop(columns=['ModelPolicy_temp', 'Reoptimize_temp'], inplace=True)\n",
    "#df.drop(columns=['Strategy', 'ModelPolicy', 'Reoptimize', 'ForecastType'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RTCS_Policy'].unique().tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for instance_name in ['winter', 'summer', 'spring', 'autumn']:\n",
    "    df_det = df[(df['Model'] == 'deterministic')&(df['InstanceName'] == instance_name)]\n",
    "    display(df_det['GammaPerc'].unique().tolist())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for instance_name in ['winter', 'summer', 'spring', 'autumn']:\n",
    "    df_rob = df[(df['Model'] == 'robust-budget')&(df['InstanceName'] == instance_name)]\n",
    "    display(df_rob['GammaPerc'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Get results only for Lookahead models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = df[(df['ModelPolicy'] == 'full_model')]\n",
    "#df['RTCS_Policy'] = df['RTCS_Policy'].str.replace('\\+ReOpt', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. VaR and CVaR functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_at_risk(returns, confidence_level=.80):\n",
    "\t\"\"\"\n",
    "\tIt calculates the Value at Risk (VaR) of some time series. It represents \n",
    "\tthe maximum loss with the given confidence level.\n",
    "\t\n",
    "\tParameters\n",
    "\t----------\n",
    "\treturns : pandas.DataFrame\n",
    "\t\tReturns of each time serie. It could be daily, weekly, monthly, ...\n",
    "\t\t\n",
    "\tconfidence_level : int\n",
    "\t\tConfidence level. 5% by default.\n",
    "\t\t\t\n",
    "\tReturns\n",
    "\t-------\n",
    "\tvar : pandas.Series\n",
    "\t\tValue at Risk for each time series.\n",
    "\t\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# Calculating VaR\n",
    "\treturns = np.asarray(returns)\n",
    "\treturn np.round(np.quantile(returns, confidence_level, axis=0, interpolation='higher'), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_shortfall(returns, confidence_level=.80):\n",
    "\t\"\"\"\n",
    "\tIt calculates the Expected Shortfall (ES) of some time series. It represents \n",
    "\tthe average loss according to the Value at Risk.\n",
    "\t\n",
    "\tParameters\n",
    "\t----------\n",
    "\treturns : pandas.DataFrame\n",
    "\t\tReturns of each time serie. It could be daily, weekly, monthly, ...\n",
    "\t\t\n",
    "\tconfidence_level : int\n",
    "\t\tConfidence level. 5% by default.\n",
    "\t\t\t\n",
    "\tReturns\n",
    "\t-------\n",
    "\tes : pandas.Series\n",
    "\t\tExpected Shortfall for each time series.\n",
    "\t\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# Calculating VaR\n",
    "\treturns = np.asarray(returns)\n",
    "\tvar = value_at_risk(returns, confidence_level)\n",
    "\t\n",
    "\t# ES is the average of the worst losses (under var)\n",
    "\treturn np.round(returns[np.greater(returns, var)].mean(), 2)  # adaptation to worst-case values (average of highest values)\n",
    "\t#return np.round(returns[np.less(returns, var)].mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_80(a):\n",
    "    return value_at_risk(a, confidence_level=.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_90(a):\n",
    "    return value_at_risk(a, confidence_level=.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_95(a):\n",
    "    return value_at_risk(a, confidence_level=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_99(a):\n",
    "    return value_at_risk(a, confidence_level=.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvar_80(a):\n",
    "    return expected_shortfall(a, confidence_level=.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvar_90(a):\n",
    "    return expected_shortfall(a, confidence_level=.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvar_95(a):\n",
    "    return expected_shortfall(a, confidence_level=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvar_99(a):\n",
    "    return expected_shortfall(a, confidence_level=.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: find duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(['InstanceName', 'Model', 'Strategy', 'Reoptimize', 'ModelPolicy', 'ForecastType', 'ModelName', 'RTCS_Policy', 'Gamma', 'GammaPerc', 'ScenarioId', 't', 'd'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['InstanceName', 'Model', 'Strategy', 'Reoptimize', 'ModelPolicy', 'ForecastType', 'ModelName', 'RTCS_Policy', 'Gamma', 'GammaPerc', 'ScenarioId', 't', 'd'], \n",
    "                   keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Merge dataframe with scenario dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the season start and end dates (northern hemisphere) for a specific year Y.\n",
    "def get_season_dates(Y):\n",
    "    return dict( {\"winter\" : [ (pd.Timestamp(year=Y, month=1, day=1, hour=0), pd.Timestamp(year=Y, month=3, day=20, hour=23, minute=59, second=59)), \n",
    "                              (pd.Timestamp(year=Y, month=12, day=21, hour=0), pd.Timestamp(year=Y, month=12, day=31, hour=23, minute=59, second=59))],\n",
    "               \"spring\" : [(pd.Timestamp(year=Y, month=3, day=21, hour=0), pd.Timestamp(year=Y, month=6, day=20, hour=23, minute=59, second=59))],\n",
    "               \"summer\" : [(pd.Timestamp(year=Y, month=6, day=21, hour=0), pd.Timestamp(year=Y, month=9, day=22, hour=23, minute=59, second=59))],\n",
    "               \"autumn\" : [(pd.Timestamp(year=Y, month=9, day=23, hour=0), pd.Timestamp(year=Y, month=12, day=20, hour=23, minute=59, second=59))] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[Japan instances] Reading scenarios from dataframe files...\")\n",
    "instance_group = 'japan-10'\n",
    "scenario_folder = os.path.join(instances_folder, \"japan_microgrid\", instance_group, \"scenarios\")\n",
    "csv_filelist = []\n",
    "for filename in glob.glob(os.path.join(scenario_folder, \"*.csv.gz\")):\n",
    "    inputfile = os.path.join(scenario_folder, filename)\n",
    "    csv_filelist.append((filename, inputfile))\n",
    "# end\n",
    "# Read all files and append to a single dataframe df\n",
    "df_list = []\n",
    "for filename, inputfile in csv_filelist:\n",
    "    print('Reading file ', filename)\n",
    "    df_s = pd.read_csv(filename)\n",
    "    df_list.append(df_s)\n",
    "# end\n",
    "df_scenarios = pd.concat(df_list)\n",
    "display(df_scenarios.info())\n",
    "# convert timestamp column to datetime\n",
    "df_scenarios['timestamp'] = pd.to_datetime(df_scenarios['timestamp'])  # DateTime.(df[!, :timestamp], dateformat\"yyyy-mm-dd HH:MM:SS\")\n",
    "first_date = df_scenarios['timestamp'].min()\n",
    "last_date = df_scenarios['timestamp'].max()\n",
    "print(first_date, last_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain instance season by extracting last part of the instance_name\n",
    "df_dict_scenarios = dict()\n",
    "for season in ['winter', 'spring', 'autumn', 'summer']:\n",
    "    print(\"[read_scenario_dataframes] Filtering scenario dataframe with season criteria: season == \", season)\n",
    "    df_list_seasonal = []\n",
    "    first_year = df_scenarios['timestamp'].min().year\n",
    "    last_year = df_scenarios['timestamp'].max().year\n",
    "    for year in range(first_year, last_year+1):\n",
    "        season_date_dict = get_season_dates(year)\n",
    "        date_list = season_date_dict[season]\n",
    "        for start_end_date_tuple in date_list:\n",
    "            start_date = start_end_date_tuple[0]\n",
    "            end_date = start_end_date_tuple[1]\n",
    "            print(\"Season {}: [{} - {}]\".format(season, start_date, end_date))\n",
    "            df_season = df_scenarios[((df_scenarios['timestamp'] >= start_date) & (df_scenarios['timestamp'] <= end_date))]\n",
    "            df_list_seasonal.append(df_season)\n",
    "        # end\n",
    "    # end\n",
    "    df_dict_scenarios[season] = pd.concat(df_list_seasonal)\n",
    "    df_dict_scenarios[season]['day'] = df_dict_scenarios[season]['timestamp'].dt.day\n",
    "    unique_day_list = df_dict_scenarios[season]['timestamp'].dt.normalize().unique()\n",
    "    print(len(unique_day_list), 'days in total')\n",
    "    scenario_count = 0\n",
    "    for unique_day in unique_day_list:\n",
    "        scenario_count += 1\n",
    "        df_dict_scenarios[season].loc[(df_dict_scenarios[season]['timestamp'].dt.normalize() == unique_day), 'ScenarioId']  = scenario_count\n",
    "    df_dict_scenarios[season]['t'] = df_dict_scenarios[season]['timestamp'].dt.hour + 1\n",
    "    df_dict_scenarios[season].loc[(df_dict_scenarios[season]['timestamp'].dt.minute == 0), 'd'] = 1\n",
    "    df_dict_scenarios[season].loc[(df_dict_scenarios[season]['timestamp'].dt.minute == 10), 'd'] = 2\n",
    "    df_dict_scenarios[season].loc[(df_dict_scenarios[season]['timestamp'].dt.minute == 20), 'd'] = 3\n",
    "    df_dict_scenarios[season].loc[(df_dict_scenarios[season]['timestamp'].dt.minute == 30), 'd'] = 4\n",
    "    df_dict_scenarios[season].loc[(df_dict_scenarios[season]['timestamp'].dt.minute == 40), 'd'] = 5\n",
    "    df_dict_scenarios[season].loc[(df_dict_scenarios[season]['timestamp'].dt.minute == 50), 'd'] = 6\n",
    "    df_dict_scenarios[season]['ScenarioId'] = df_dict_scenarios[season]['ScenarioId'].astype(int)\n",
    "    df_dict_scenarios[season]['t'] = df_dict_scenarios[season]['t'].astype(int)\n",
    "    df_dict_scenarios[season]['d'] = df_dict_scenarios[season]['d'].astype(int)\n",
    "# end\n",
    "display(df_dict_scenarios['winter'].head(10))\n",
    "#display(df_dict_scenarios['winter'].info())\n",
    "# df_dict_scenarios[season]['PV_Production_Wh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Calculate Out Of Contract (OC) Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_OC_cost(microgrid):\n",
    "    if microgrid == 'utc':\n",
    "        oc_cost = [0.0197817, 0.0197817, 0.0197817, 0.0197817, 0.0197817, 0.0197817, 0.025343, 0.040525, 0.0340525, 0.045779, 0.045779, 0.045779, 0.0385546, 0.0391196, 0.0390639, 0.0390639, 0.0390639, 0.0388545, 0.0420445, 0.0331963, 0.0268793, 0.037982, 0.0290351, 0.0227148]\n",
    "    else:  # japan\n",
    "        oc_cost = [0.01499000, 0.01499000, 0.01499000, 0.01499000, 0.01499000, 0.02998000, 0.02998000, 0.02998000, 0.06275000, 0.06275000, 0.02998000, 0.02998000, 0.02998000, 0.02998000, 0.02998000, 0.02998000, 0.02998000, 0.06275000, 0.06275000, 0.02998000, 0.02998000, 0.01499000, 0.01499000]\n",
    "    d = {'t': [_ for _ in range(1, len(oc_cost)+1)], 'oc_unit_cost': oc_cost}\n",
    "    df_oc = pd.DataFrame(data=d)\n",
    "    return df_oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_OC_cost('japan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcular as estatisticas de state of charge das baterias, em cada instante de tempo t : Stored Avg"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!conda install -c conda-forge numba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numba import jit\n",
    "#@jit(nopython=True)\n",
    "def calculate_each_soc(scenario_id, g_td, h_td, uInit, lost_coeff = 0.15):  # e.g. lost_coeff = 0.1 (10 %)\n",
    "    soc = np.empty(h_td.shape[0])\n",
    "    last_scenario_id = -1\n",
    "    for i in range(0, h_td.shape[0]):\n",
    "        if scenario_id[i] != last_scenario_id:\n",
    "            soc[i] = uInit + (1 - lost_coeff) * (g_td[i]) - h_td[i]\n",
    "        else:\n",
    "            soc[i] = soc[i-1] + (1 - lost_coeff) * (g_td[i]) - h_td[i]\n",
    "        last_scenario_id = scenario_id[i]\n",
    "    return soc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_battery_soc(df_b, uInit = 100000, uMax = 309700):\n",
    "    df_b.sort_values(by=['ScenarioId', 't', 'd'], inplace=True)\n",
    "    df_b['SOC'] = 100.0 * calculate_each_soc(*df_b[['ScenarioId', 'g_td', 'h_td']].values.T, uInit) / uMax  # df.loc[~((df['t'] == 1) & (df['d'] == 1))], df.loc[~((df['t'] == 1) & (df['d'] == 1)), ['SOC']].shift(-1))\n",
    "    return df_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcular o % de instantes de tempo t em que houve cobranca fora de contrato (OC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_penalty_freq(df_b):\n",
    "    df_group = df_b.groupby(by=['ScenarioId', 't']).sum()\n",
    "    total = len(df_group.index)\n",
    "    df_occurence = df_group[df_group['e_td_x'] >= 0.1]\n",
    "    num_occurence = len(df_occurence.index)\n",
    "    return 100 * num_occurence / float(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcular o % de utilizacao da energia solar (vide instantes em que o gap > 0) : Renewables Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_renewables_util(df_b, season):\n",
    "    df_plus_scenarios = df_b.merge(df_dict_scenarios[season], on=['ScenarioId', 't', 'd'])\n",
    "    df_group = df_plus_scenarios.groupby(by=['ScenarioId', 't']).sum()\n",
    "    df_group['min_gap_PV'] = df_group[['gap','PV_Production_Wh']].min(axis=1)\n",
    "    df_group['Renewables Util'] = 100 * (df_group['gap'] <= 0).astype(int) + 100 * (df_group['gap'] > 0).astype(int) * (1.0 - (df_group['min_gap_PV'] / df_group['PV_Production_Wh']))\n",
    "    return df_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Simulation snapshot graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oc_cost = calculate_OC_cost('japan')\n",
    "# multiplicando o consumo pelos custos OC para cada periodo t, em separado\n",
    "df_with_oc_cost = df.merge(df_oc_cost, on=['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_oc_cost['oc_cost'] = df_with_oc_cost['oc_unit_cost'] * df_with_oc_cost['e_td_x']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_dict_scenarios[instance_name].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display(sorted(df_['ScenarioId'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_[(df_['Model'] == 'deterministic')]['RTCS_Policy'].unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_all.drop_duplicates(subset=['timestamp', 'ScenarioId', 't', 'd'], \n",
    "                   keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_OC_for_scenario(instance_name, df_dict_scenarios, df, which_scenario, \n",
    "                         strategy, gamma_det, gamma_rob):\n",
    "    df_ = df.copy()\n",
    "    df_ = df_[(df_['InstanceName'] == instance_name)]\n",
    "    df_ = df_[(df_['RTCS_Policy'] == strategy)]\n",
    "    #df_ = df_[(df_['ScenarioId'] == which_scenario)]\n",
    "    # Filter out scenarios where OC-cost == 0\n",
    "    oc_cost_det = df_[(df_['Model'] == 'deterministic') & (df_['GammaPerc'] == gamma_det)]['e_td_x'].sum()\n",
    "    if oc_cost_det <= 1.0:\n",
    "        display(f'Skipping scenario {which_scenario}, since sum-OC-cost-det == 0.')\n",
    "        return\n",
    "    else:\n",
    "        display(f'Plot of scenario {which_scenario}. sum-OC-cost-det = {oc_cost_det}')\n",
    "    \n",
    "    df_scenario_info = df_dict_scenarios[instance_name]\n",
    "    df_scenario_info = df_scenario_info[(df_scenario_info['ScenarioId'] == which_scenario)]\n",
    "\n",
    "    df_det = df_[(df_['Model'] == 'deterministic')]\n",
    "\n",
    "    # merge the results df with the instance scenario info df\n",
    "    df_all = df_scenario_info.merge(df_, how='inner', on=['ScenarioId', 't', 'd'])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    # the size of A4 paper\n",
    "    fig.set_size_inches(11.7, 8.27)\n",
    "    df_scenario_info.plot(x=\"timestamp\", y=\"PV_Production_Wh\", ax=ax, legend=False, color=\"b\")\n",
    "    df_scenario_info.plot(x=\"timestamp\", y=\"Building_Consumption_Wh\", ax=ax, legend=False, color=\"g\")\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    df_det = df_all[(df_all['Model'] == 'deterministic')]\n",
    "    #display(df_det['GammaPerc'].unique().tolist())\n",
    "    df_det = df_det[(df_det['GammaPerc'] == gamma_det)].rename(columns={\"e_td_x\": \"OC-det\"})\n",
    "    #display('Det')\n",
    "    #display(df_det['OC-det'])\n",
    "    df_det.plot(x=\"timestamp\", y=\"OC-det\", ax=ax2, legend=False, color=\"r\")\n",
    "\n",
    "    df_rob = df_all[(df_all['Model'] == 'robust-budget')]\n",
    "    #display(df_rob['GammaPerc'].unique().tolist())\n",
    "    df_rob = df_rob[(df_rob['GammaPerc'] == gamma_rob)].rename(columns={\"e_td_x\": \"OC-rob\"})\n",
    "    #display('Rob')\n",
    "    #display(df_rob.head())\n",
    "    df_rob.plot(x=\"timestamp\", y=\"OC-rob\", ax=ax2, legend=False, color=\"y\")\n",
    "\n",
    "    ax.figure.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instance_name, gamma_det, gamma_rob = 'summer', 50, 40\n",
    "#instance_name, gamma_det, gamma_rob = 'autumn', 50, 60\n",
    "\n",
    "strategy = 'cheapest+LA+ReOpt'\n",
    "df_temp = df_with_oc_cost[(df_with_oc_cost['InstanceName'] == instance_name)]\n",
    "df_temp = df_temp[(df_temp['RTCS_Policy'] == strategy)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_ = df_temp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_s = df_[(df_['Model'] == 'deterministic') & (df_['GammaPerc'] == 50) & (df['ScenarioId'] == 1)]\n",
    "df_s[df_s['oc_cost'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_higher_det_cost_for_scenario(df_oc_cost, df_dict_scenarios, df, which_scenario, gamma_det, gamma_rob,\n",
    "                                     start_time = None, end_time = None, cum_sum = False, plot_oc = True):\n",
    "    df_ = df.copy()\n",
    "    \n",
    "    df_ = df_[(df_['ScenarioId'] == which_scenario)]\n",
    "    # Filter out scenarios where OC-cost == 0\n",
    "    df_oc_cost_det = df_[(df_['Model'] == 'deterministic') & (df_['GammaPerc'] == gamma_det)]\n",
    "    max_oc_cost_det = df_oc_cost_det['oc_cost'].max()\n",
    "    sum_oc_cost_det = df_oc_cost_det['oc_cost'].sum()\n",
    "    if sum_oc_cost_det <= 1.0:\n",
    "        display(f'Skipping scenario {which_scenario}, since sum-OC-cost-det == 0.')\n",
    "        return\n",
    "    else:\n",
    "        display(f'Plot of scenario {which_scenario}. sum-OC-cost-det = {sum_oc_cost_det} and max_oc_cost_det = {max_oc_cost_det}.')\n",
    "        \n",
    "    # Filter out scenarios, selecting those where det cost went higher than rob-cost at least once\n",
    "    cost_det = df_[(df_['Model'] == 'deterministic') & (df_['GammaPerc'] == gamma_det)]\n",
    "    cost_rob = df_[(df_['Model'] == 'robust-budget') & (df_['GammaPerc'] == gamma_rob)]\n",
    "    cost_all = cost_det.merge(cost_rob, how='inner', on=['ScenarioId', 't', 'd'])\n",
    "    cost_all['det_higher'] = (cost_all['cost_x'] > cost_all['cost_y']).astype(int)\n",
    "    sum_high_cost_det = cost_all['det_higher'].sum()\n",
    "    if sum_high_cost_det <= 1.0:\n",
    "        display(f'Skipping scenario {which_scenario}, since sum_high_cost_det == 0.')\n",
    "        return\n",
    "    else:\n",
    "        display(f'Plot of scenario {which_scenario}. sum_high_cost_det = {sum_high_cost_det}')\n",
    "    \n",
    "    df_scenario_info = df_dict_scenarios[instance_name]\n",
    "    df_scenario_info = df_scenario_info[(df_scenario_info['ScenarioId'] == which_scenario)]\n",
    "\n",
    "    # merge the results df with the instance scenario info df\n",
    "    df_all = df_scenario_info.merge(df_, how='inner', on=['ScenarioId', 't', 'd'])\n",
    "    if start_time is not None:\n",
    "        df_all.set_index(['timestamp'], inplace=True)\n",
    "        df_all = df_all.between_time(start_time, end_time)\n",
    "        df_all.reset_index(inplace=True)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    # the size of A4 paper\n",
    "    fig.set_size_inches(15.7, 8.27)\n",
    "    #df_scenario_info.plot(x=\"timestamp\", y=\"PV_Production_Wh\", ax=ax, legend=False, color=\"b\", marker='+')\n",
    "    if cum_sum:\n",
    "        df_scenario_info['Building_Consumption_Wh_cumsum'] = df_scenario_info['Building_Consumption_Wh'].cumsum()\n",
    "        df_scenario_info.plot(x=\"timestamp\", y=\"Building_Consumption_Wh_cumsum\", ax=ax, legend=False, color=\"g\", marker='^')\n",
    "    else:\n",
    "        df_scenario_info.plot(x=\"timestamp\", y=\"Building_Consumption_Wh\", ax=ax, legend=False, color=\"g\", marker='^')\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    df_det = df_all[(df_all['Model'] == 'deterministic')]\n",
    "    #display(df_det['GammaPerc'].unique().tolist())\n",
    "    df_det = df_det[(df_det['GammaPerc'] == gamma_det)].rename(columns={\"cost\": \"cost-det\", \"oc_cost\": \"OC-det\"})\n",
    "    ###display('Det')\n",
    "    ###display(df_det['OC-det'])\n",
    "\n",
    "    df_rob = df_all[(df_all['Model'] == 'robust-budget')]\n",
    "    #display(df_rob['GammaPerc'].unique().tolist())\n",
    "    df_rob = df_rob[(df_rob['GammaPerc'] == gamma_rob)].rename(columns={\"cost\": \"cost-rob\", \"oc_cost\": \"OC-rob\"})\n",
    "    ###display('Rob')\n",
    "    ###display(df_rob.head())\n",
    "    if cum_sum:\n",
    "        label_det = \"-det-cum\"\n",
    "        label_rob = \"-rob-cum\"\n",
    "        df_det[\"cost-det-cum\"] = df_det[\"cost-det\"].cumsum()\n",
    "        df_rob[\"cost-rob-cum\"] = df_rob[\"cost-rob\"].cumsum()\n",
    "        df_det[\"OC-det-cum\"] = df_det[\"OC-det\"].cumsum()\n",
    "        df_rob[\"OC-rob-cum\"] = df_rob[\"OC-rob\"].cumsum()\n",
    "    else:\n",
    "        label_det = \"-det\"\n",
    "        label_rob = \"-rob\"\n",
    "    # end if\n",
    "    df_det.plot(x=\"timestamp\", y='cost'+label_det, ax=ax2, legend=False, color=\"r\", marker='>')\n",
    "    df_rob.plot(x=\"timestamp\", y='cost'+label_rob, ax=ax2, legend=False, color=\"y\", marker='x')\n",
    "    if plot_oc:\n",
    "        df_det.plot(x=\"timestamp\", y=\"OC\"+label_det, ax=ax2, legend=False, color=\"purple\", marker='o')\n",
    "        df_rob.plot(x=\"timestamp\", y=\"OC\"+label_rob, ax=ax2, legend=False, color=\"grey\", marker='o')\n",
    "    # end if\n",
    "    \n",
    "    ax.grid('on', which='minor', axis='x' )\n",
    "    ax.grid('on', which='major', axis='x' )\n",
    "    ax.grid('on', which='minor', axis='y' )\n",
    "    ax.grid('on', which='major', axis='y' )\n",
    "    \n",
    "\n",
    "    ax.figure.legend()\n",
    "    plt.show()\n",
    "    del df_\n",
    "    del cost_det\n",
    "    del cost_rob\n",
    "    del cost_all\n",
    "    del df_scenario_info\n",
    "    del df_det\n",
    "    del df_rob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scenario 170 - 9, 9\n",
    "# scenario 181 - 6, 12 - 'autumn', 50, 40\n",
    "# sc 197 - 07:00 - 09:00\n",
    "plot_higher_det_cost_for_scenario(df_oc_cost, df_dict_scenarios, df_temp, 181, gamma_det, gamma_rob, '07:00', '10:30',\n",
    "                                 cum_sum = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scenario 170 - 9, 9\n",
    "# scenario 181 - 6, 12 - 'autumn', 50, 40\n",
    "# sc 197 - 07:00 - 09:00\n",
    "plot_higher_det_cost_for_scenario(df_oc_cost, df_dict_scenarios, df_temp, 181, gamma_det, gamma_rob, \n",
    "                                 cum_sum = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Accumulated costs after all scenario runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_costs_all_scenarios(df_all, cum_sum = False, plot_oc = True):\n",
    "    \n",
    "    \n",
    "    #df_all = df_all[(df_all['timestamp'].dt.year == year)]\n",
    "    df_all = df_all.sort_values(by=['timestamp'])\n",
    "    df_all['Building_Consumption (Wh)'] = df_all['Building_Consumption_Wh'].cumsum()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax2 = ax.twinx()\n",
    "    # the size of A4 paper\n",
    "    fig.set_size_inches(15.7, 8.27)\n",
    "    plot = True\n",
    "    if plot:\n",
    "        df_all.plot(x=\"timestamp\", y=\"Building_Consumption (Wh)\", ax=ax2, legend=False, color=\"g\") #, marker='^')\n",
    "        #df_all.plot(x=\"timestamp\", y=\"PV_Production_Wh\", ax=ax, legend=False, color=\"b\")  #, marker='+')\n",
    "\n",
    "    #df_all = df_all.sort_values(by=['timestamp'])\n",
    "    df_det = df_all[df_all['Model'] == 'deterministic'].sort_values(by=['timestamp'])\n",
    "    df_det['OC-Cost-Det (Euros)'] = df_det['OC-det'].cumsum()\n",
    "    df_det['Total-Cost-Det (Euros)'] = df_det['cost-det'].cumsum()\n",
    "    df_rob = df_all[df_all['Model'] == 'robust-budget'].sort_values(by=['timestamp'])\n",
    "    df_rob['OC-Cost-Rob (Euros)'] = df_rob['OC-rob'].cumsum()\n",
    "    df_rob['Total-Cost-Rob (Euros)'] = df_rob['cost-rob'].cumsum()\n",
    "    \n",
    "    label_det = \"-Det_Euros\"\n",
    "    label_rob = \"-Rob_Euros\"\n",
    "    df_det.plot(x=\"timestamp\", y='Total-Cost-Det (Euros)', ax=ax, legend=False, color=\"r\") #, marker='>')\n",
    "    df_rob.plot(x=\"timestamp\", y='Total-Cost-Rob (Euros)', ax=ax, legend=False, color=\"y\") #, marker='x')\n",
    "    if plot_oc:\n",
    "        df_det.plot(x=\"timestamp\", y='OC-Cost-Det (Euros)', ax=ax, legend=False, color=\"purple\") #, marker='o')\n",
    "        df_rob.plot(x=\"timestamp\", y='OC-Cost-Rob (Euros)', ax=ax, legend=False, color=\"grey\") #, marker='o')\n",
    "    # end if\n",
    "    \n",
    "    ax.grid('on', which='minor', axis='x' )\n",
    "    ax.grid('on', which='major', axis='x' )\n",
    "    ax.grid('on', which='minor', axis='y' )\n",
    "    ax.grid('on', which='major', axis='y' )\n",
    "    \n",
    "    ax.set_xlabel(\"Scenario (Date)\")\n",
    "    ax2.set_ylabel('Energy (Wh)')\n",
    "    ax.set_ylabel('Cost (Euros)')\n",
    "\n",
    "    #ax.figure.legend()\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "    fig.savefig('cumulative_costs_time_horizon.pdf')\n",
    "    print('Final costs:')\n",
    "    print('Det:\\n', df_det.iloc[-1])\n",
    "    print('Rob:\\n', df_rob.iloc[-1])\n",
    "    del df_det\n",
    "    del df_rob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_gamma_dict = {'summer' : (50, 40), 'winter' : (100, 100), 'autumn' : (50, 40), 'spring' : (50, 40)}\n",
    "df_list = []\n",
    "strategy = 'cheapest+LA+ReOpt'\n",
    "df_all = df_with_oc_cost[(df_with_oc_cost['RTCS_Policy'] == strategy)]\n",
    "for instance_name in ['summer', 'winter', 'autumn', 'spring']:\n",
    "    df_scenario_info = df_dict_scenarios[instance_name]\n",
    "    \n",
    "    df_det = df_all[(df_all['Model'] == 'deterministic') & (df_all['InstanceName'] == instance) & (df_all['GammaPerc'] == instance_gamma_dict[instance][0])]\n",
    "    df_det = df_det.rename(columns={\"cost\": \"cost-det\", \"oc_cost\": \"OC-det\"})\n",
    "    df_det = df_scenario_info.merge(df_det, how='inner', on=['ScenarioId', 't', 'd'])\n",
    "    df_list.append(df_det)\n",
    "    \n",
    "    df_rob = df_all[(df_all['Model'] == 'robust-budget') & (df_all['InstanceName'] == instance) & (df_all['GammaPerc'] == instance_gamma_dict[instance][1])]\n",
    "    df_rob = df_rob.rename(columns={\"cost\": \"cost-rob\", \"oc_cost\": \"OC-rob\"})\n",
    "    df_rob = df_scenario_info.merge(df_rob, how='inner', on=['ScenarioId', 't', 'd'])\n",
    "    df_list.append(df_rob)\n",
    "# end for\n",
    "df_temp = pd.concat(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_costs_all_scenarios(df_temp, cum_sum = True, plot_oc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 0. Number of scenarios per instance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_scenarios_per_instance = df[((df['t'] == 1) & (df['d'] == 1))].groupby(by=['InstanceName', 'Model', 'ModelName', 'RTCS_Policy', 'GammaPerc']).count().reset_index()\n",
    "df_num_scenarios_per_instance = df_num_scenarios_per_instance[['InstanceName', 'Model', 'ModelName', 'RTCS_Policy', 'Gamma', 'GammaPerc', 'ScenarioId']]\n",
    "df_num_scenarios_per_instance.rename(columns={'ScenarioId' : 'ScenarioCount'}, inplace=True)\n",
    "df_num_scenarios_per_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1. Simulation performance given all instances \n",
    "\n",
    "Model-wise RTCS simulation performance comparison, given all instances.\n",
    "\n",
    "* Median, Mean, Std. dev and sum of each measure (cost, e_td, gap, time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data\n",
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "def compute_ci(a, conf=0.95):\n",
    "    return [np.round(_, 2) for _ in st.t.interval(conf, len(a)-1, loc=np.mean(a), scale=st.sem(a))]\n",
    "\n",
    "def compute_iqr(a):\n",
    "    return st.iqr(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_instance_stats = dict()\n",
    "instances_to_process = df['InstanceName'].unique().tolist()\n",
    "for instance_name in instances_to_process:  # group by instance\n",
    "    df_itype = df[(df['InstanceName'] == instance_name)]\n",
    "    _model_list = df_itype['Model'].unique().tolist()\n",
    "    for model in _model_list:\n",
    "        df_model = df_itype[df_itype['Model'] == model]\n",
    "        _gamma_perc_list = df_model['GammaPerc'].unique().tolist()\n",
    "        for gamma_perc in _gamma_perc_list:\n",
    "            df_gamma = df_model[df_model['GammaPerc'] == gamma_perc]\n",
    "            policy_list = df_gamma['RTCS_Policy'].unique().tolist()\n",
    "            for policy in policy_list:\n",
    "                  df_ = df_gamma[df_gamma['RTCS_Policy'] == policy]\n",
    "                  reopt = df_['Reoptimize'].iloc[0]\n",
    "                  strategy = df_['Strategy'].iloc[0]\n",
    "                  df_oc_cost = calculate_OC_cost('japan')\n",
    "                  # multiplicando o consumo pelos custos OC para cada periodo t, em separado\n",
    "                  df_ = df_.merge(df_oc_cost, on=['t'])\n",
    "                  df_['oc_cost'] = df_['oc_unit_cost'] * df_['e_td_x']\n",
    "                  df_ungrouped = df_.copy()\n",
    "                  df_ = df_.groupby(by=['ScenarioId']).sum()\n",
    "                  key = (instance_name, model, gamma_perc, policy, strategy, reopt)\n",
    "                  per_instance_stats[key] = dict()\n",
    "                  #per_instance_stats[key]['% Best Performance'] = calculate_perc_best_performance(df_instance, model)\n",
    "                  #per_instance_stats[key]['% Solved'] = calculate_perc_solved(df_rpfs, model, instance_type, instance_size)\n",
    "                  #per_instance_stats[key]['Avg. % gap'] = calculate_avg_perc_gap(df_instance, model)\n",
    "                  per_instance_stats[key]['Median time (s)'] = np.round(df_['RealProcTime'].median(), 2)\n",
    "                  per_instance_stats[key]['Avg. time (s)'] = np.round(df_['RealProcTime'].mean(), 2)\n",
    "                  per_instance_stats[key]['Std. dev. of time (s)'] = np.round(df_['RealProcTime'].std(), 2)\n",
    "                  per_instance_stats[key]['Total time (s)'] = np.round(df_['RealProcTime'].sum(), 2)\n",
    "                  \n",
    "                  per_instance_stats[key]['Median cost ($)'] = np.round(df_['cost'].median(), 2)\n",
    "                  per_instance_stats[key]['Cost Avg ($)'] = np.round(df_['cost'].mean(), 2)\n",
    "                  per_instance_stats[key]['Cost Std ($)'] = np.round(df_['cost'].std(), 2)\n",
    "                  per_instance_stats[key]['Cost Total (M$)'] = np.round(df_['cost'].sum() / 1000.0, 2)\n",
    "                  per_instance_stats[key]['Cost Max ($)'] = np.round(df_['cost'].max(), 2)\n",
    "                  per_instance_stats[key]['Cost VaR 80% ($)'] = np.round(var_80(df_['cost']), 2)\n",
    "                  per_instance_stats[key]['Cost VaR 90% ($)'] = np.round(var_90(df_['cost']), 2)\n",
    "                  per_instance_stats[key]['Cost VaR 95% ($)'] = np.round(var_95(df_['cost']), 2)\n",
    "                  per_instance_stats[key]['Cost VaR 99% ($)'] = np.round(var_99(df_['cost']), 2)\n",
    "                  per_instance_stats[key]['Cost CVaR 80% ($)'] = np.round(cvar_80(df_['cost']), 2)\n",
    "                  per_instance_stats[key]['Cost CVaR 90% ($)'] = np.round(cvar_90(df_['cost']), 2)\n",
    "                  per_instance_stats[key]['Cost CVaR 95% ($)'] = np.round(cvar_95(df_['cost']), 2)\n",
    "                  per_instance_stats[key]['Cost CVaR 99% ($)'] = np.round(cvar_99(df_['cost']), 2)\n",
    "                    \n",
    "                  per_instance_stats[key]['Cost IQR ($)'] = compute_iqr(df_['cost'])\n",
    "                  \n",
    "                  per_instance_stats[key]['Median gap (kWh)'] = np.round(df_['gap'].median(), 2)\n",
    "                  per_instance_stats[key]['Avg. gap (kWh)'] = np.round(df_['gap'].mean(), 2)\n",
    "                  per_instance_stats[key]['Std. dev. of gap (kWh)'] = np.round(df_['gap'].std(), 2)\n",
    "                  per_instance_stats[key]['Total gap (kWh)'] = np.round(df_['gap'].sum(), 2)\n",
    "                  \n",
    "                  per_instance_stats[key]['OC Cost Median ($)'] = np.round(df_['oc_cost'].median(), 2)\n",
    "                  per_instance_stats[key]['OC Cost Avg ($)'] = np.round(df_['oc_cost'].mean(), 2)\n",
    "                  per_instance_stats[key]['OC Cost Std ($)'] = np.round(df_['oc_cost'].std(), 2)\n",
    "                  per_instance_stats[key]['OC Cost Total ($)'] = np.round(df_['oc_cost'].sum(), 2)\n",
    "                \n",
    "                  # Calcular o % de instantes de tempo t em que houve cobranca fora de contrato (OC)\n",
    "                  per_instance_stats[key]['Penalty Freq (%)'] = calculate_penalty_freq(df_ungrouped)\n",
    "                \n",
    "                  # Calcular as estatisticas de state of charge das baterias, em cada instante de tempo t : Stored Avg\n",
    "                  df_soc = calculate_battery_soc(df_ungrouped)\n",
    "                  #df_soc = df_ungrouped.copy()\n",
    "                  #df_soc['SOC'] = 0\n",
    "                  per_instance_stats[key]['SOC Median (%)'] = np.round(df_soc['SOC'].median(), 2)\n",
    "                  per_instance_stats[key]['SOC Avg (%)'] = np.round(df_soc['SOC'].mean(), 2)\n",
    "                  per_instance_stats[key]['SOC Std (%)'] = np.round(df_soc['SOC'].std(), 2)\n",
    "                  per_instance_stats[key]['SOC CI (%)'] = compute_ci(df_soc['SOC'])\n",
    "                  per_instance_stats[key]['SOC IQR (%)'] = compute_iqr(df_soc['SOC'])\n",
    "                  #per_instance_stats[key]['Stored Total'] = np.round(df_soc['SOC'].sum(), 2)\n",
    "                    \n",
    "                  # Calcular o % de utilizacao da energia solar (vide instantes em que o gap > 0) : Renewables Util\n",
    "                  df_ren = calculate_renewables_util(df_ungrouped, instance_name)\n",
    "                  per_instance_stats[key]['Renewables Util Median (%)'] = np.round(df_ren['Renewables Util'].median(), 2)\n",
    "                  per_instance_stats[key]['Renewables Util Avg (%)'] = np.round(df_ren['Renewables Util'].mean(), 2)\n",
    "                  per_instance_stats[key]['Renewables Util Std (%)'] = np.round(df_ren['Renewables Util'].std(), 2)\n",
    "                  per_instance_stats[key]['Renewables Util IQR (%)'] = compute_iqr(df_ren['Renewables Util'])\n",
    "                  #per_instance_stats[key]['Renewables Util Total'] = np.round(df_ren['Renewables Util'].sum(), 2)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table1 = pd.DataFrame.from_dict(per_instance_stats)\n",
    "df_table1b = df_table1.T.reset_index()\n",
    "df_table1b.rename(columns={'level_0': 'Instance', 'level_1' : 'Model', 'level_2' : 'Gamma', 'level_3' : 'RTCS Policy',\n",
    "                          'level_4' : 'Strategy', 'level_5' : 'Reoptimize'}, inplace=True)\n",
    "df_table1b.head(12)\n",
    "df_table1b.to_pickle(os.path.join(reportfolder, 'df_japan_table1.pkl.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table1b.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars = ['Instance', 'Model', 'Gamma', 'RTCS Policy', 'Strategy', 'Reoptimize']\n",
    "value_vars = [_ for _ in df_table1b.columns if _ not in id_vars]\n",
    "df_stats = pd.melt(df_table1b, id_vars=id_vars, value_vars=value_vars, value_name='value')\n",
    "df_stats.to_csv(os.path.join(reportfolder_table, 'japan-stats.csv'))\n",
    "#df_stats.to_excel(os.path.join(reportfolder_table, 'japan-stats.xlsx'))\n",
    "print('Saved to folder', reportfolder)\n",
    "df_stats.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Pareto front: cost and std average obtained by different models (several Gamma values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyle_tuple = [\n",
    "     ('dotted',                (0, (1, 1))),\n",
    "     ('dashed',                (0, (5, 5))),\n",
    "     ('densely dashed',        (0, (5, 1))),\n",
    "     ('dashdotdotted',         (0, (3, 5, 1, 5, 1, 5))),\n",
    "     ('densely dashdotdotted', (0, (3, 1, 1, 1, 1, 1))),\n",
    "\n",
    "     ('dashdotted',            (0, (3, 5, 1, 5))),\n",
    "     ('densely dashdotted',    (0, (3, 1, 1, 1))),\n",
    "     \n",
    "     ('loosely dashed',        (0, (5, 10))),\n",
    "     ('loosely dashdotted',    (0, (3, 10, 1, 10))),\n",
    "     \n",
    "\n",
    "     ('loosely dashdotdotted', (0, (3, 10, 1, 10, 1, 10))),\n",
    "     ('densely dotted',        (0, (1, 1))),\n",
    "     ('loosely dotted',        (0, (1, 10)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for season in ['winter', 'spring', 'autumn', 'summer']:\n",
    "    df_pareto = df_table1b[(df_table1b['Instance'] == season)] # & (df_table1b['RTCS Policy'] == 'cheapest+LA+ReOpt')]\n",
    "    df_pareto = df_pareto[(df_pareto['Model'] != 'robust-box')]\n",
    "    df_pareto = df_pareto[(df_pareto['Strategy'] != 'audacious')]\n",
    "    policy_list = ['conservative+LA+ReOpt', 'conservative+LA', 'cheapest+LA+ReOpt', 'cheapest+LA', 'naive']\n",
    "    df_pareto = df_pareto[(df_pareto['RTCS Policy'].isin(policy_list))]\n",
    "    df_pareto['RTCS Policy'] = df_pareto['RTCS Policy'].replace({'conservative+LA+ReOpt': 'conservative+ReOpt', \n",
    "                                          'conservative+LA': 'conservative', \n",
    "                                          'cheapest+LA+ReOpt': 'cheapest+ReOpt',\n",
    "                                          'cheapest+LA': 'cheapest'\n",
    "                                         })\n",
    "    df_pareto.rename(columns={'Cost Std ($)' : 'Cost std over all simulated scenarios (Euros)',\n",
    "                              'Cost Avg ($)' : 'Cost average over all simulated scenarios (Euros)'\n",
    "                             }, inplace=True)\n",
    "\n",
    "    df_pareto['Model / RTCS Policy'] = df_pareto['Model'] + ' / ' + df_pareto['RTCS Policy'].astype(str)\n",
    "    #display(df_pareto[['Instance', 'Model', 'RTCS Policy', 'Gamma', 'Cost Std ($)', 'Cost Avg ($)']])\n",
    "    fig, ax = plt.subplots()\n",
    "    # the size of A4 paper\n",
    "    fig.set_size_inches(10.7, 8.27)\n",
    "    fig.suptitle(f'Pareto front - {season}', fontsize=20)\n",
    "    #linestyle = [linestyle_tuple[i][1] for i in range(len(linestyle_tuple))]\n",
    "    linestyle = ['--', '-.', ':', 'dashed', 'dashdot', 'dotted', 'solid', '-', '-.',    '--', '-.', ':', 'dashed', 'dashdot', 'dotted', 'solid', '-', '-.']\n",
    "    markers = ['d', '>', '<', 'x', '^', 'v', 's', 'o', 'D',  '*', '+', 'o', 'x', '^', '8', 's', 'p', 'D']\n",
    "    #marker = marker[::-1]\n",
    "    linewidth = 1.6\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        sns.lineplot(ax=ax, data=df_pareto, x='Cost std over all simulated scenarios (Euros)', \n",
    "                     y='Cost average over all simulated scenarios (Euros)', hue='Model / RTCS Policy', \n",
    "                     style='Model / RTCS Policy',\n",
    "                     #linestyle=linestyle, \n",
    "                     markers=True)\n",
    "        sns.set_context(\"paper\", font_scale=1.2) #, rc={\"grid.linewidth\": 1, \"lines.linewidth\": linewidth})\n",
    "        fig.savefig(f'pareto_{season}.pdf')\n",
    "# end for\n",
    "\n",
    "#g = sns.FacetGrid(df_pareto, hue=\"Model\", size=8)\n",
    "#g.map(plt.scatter, 'Cost Std ($)', 'Cost Avg ($)')\n",
    "#g.map(plt.plot, 'Cost Std ($)', 'Cost Avg ($)')\n",
    "#plot_pareto_front_all_policies(df_pareto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2. Total cost considering all simulations for a specific CCP model and RTCS policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_totals = df.drop(columns=['t', 'd', 'OptTimeSpent']).groupby(by=['InstanceName', 'Model', 'GammaPerc', 'Gamma', 'RTCS_Policy']).sum()\n",
    "df_total_proc_time = df_totals.drop(columns=['ScenarioId', 'e_td_x', 'gap', 'ObjValue', 'cost'])\n",
    "df_total_cost = df_totals.drop(columns=['ScenarioId', 'e_td_x', 'gap', 'ObjValue', 'RealProcTime']).reset_index()\n",
    "# total simulation cost of the deterministic model\n",
    "df_total_cost_det = df_total_cost[(df_total_cost['Model'] == 'deterministic')].drop(columns=['Model', 'GammaPerc', 'Gamma']).rename(columns={\"cost\": \"cost(det)\"})\n",
    "# total simulation cost of the box model\n",
    "df_total_cost_box = df_total_cost[(df_total_cost['Model'] == 'robust-box')].drop(columns=['Model', 'GammaPerc', 'Gamma']).rename(columns={\"cost\": \"cost(box)\"})\n",
    "# total simulation cost of the budget model\n",
    "df_total_cost_bud = df_total_cost[(df_total_cost['Model'] == 'robust-budget')].drop(columns=['Model']).rename(columns={\"cost\": \"cost(bud)\"})\n",
    "df_total_cost_bud_pivot = pd.pivot_table(df_total_cost_bud, values='cost(bud)', index=['InstanceName', 'RTCS_Policy'], \\\n",
    "                                         columns=['GammaPerc'], aggfunc=np.sum)\n",
    "df_total_cost_bud_pivot.columns = [('Cost(bud_' + str(_) + ')') for _ in df_total_cost_bud_pivot.columns]\n",
    "df_total_cost_bud_pivot = df_total_cost_bud_pivot.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_cost_bud_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join the det, box and bud costs in the same dataframe for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_columns_total_cost = ['InstanceName', 'RTCS_Policy']\n",
    "df_total_cost_join = df_total_cost_det.merge(df_total_cost_bud_pivot, on=join_columns_total_cost, suffixes=('', '_bud'))\n",
    "#.merge(df_total_cost_box, on=join_columns_total_cost, suffixes=('_det', '_box'))\\\n",
    "#df_total_cost_join.loc[(), 'Gamma'] = np.nan\n",
    "#df_total_cost_join.loc[(), 'GammaPerc'] = np.nan\n",
    "df_total_cost_join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3. Cost of the most expensive scenario (worst simulation cost), grouped by CCP model and simulation parameters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t2 = df.drop(columns=['t', 'd', 'OptTimeSpent', 'ObjValue'])\n",
    "df_t2 = df_t2.groupby(by=['InstanceName', 'Model', 'ModelName', 'RTCS_Policy', 'ScenarioId']).sum().\\\n",
    "    drop(columns=['e_td_x', 'gap', 'RealProcTime', 'GammaPerc', 'Gamma']).\\\n",
    "    groupby(by=['InstanceName', 'Model', 'ModelName', 'RTCS_Policy']).\\\n",
    "    max()\n",
    "\n",
    "df_rob = df_t2.reset_index()\n",
    "df_rob = df_rob[(df_rob['Model'] == 'robust-budget') | (df_rob['Model'] == 'robust-box')]\n",
    "df_det = df_t2.reset_index().drop(columns=['ModelName'])\n",
    "df_det = df_det[df_det['Model'] == 'deterministic']\n",
    "df_wins_t2 = df_rob.merge(df_det, on=['InstanceName', 'RTCS_Policy'], suffixes=('_rob', '_det'))\\\n",
    "    .drop(columns=['Model_det'])\n",
    "df_wins_t2['MaxRobCost_Smaller'] = (df_wins_t2['cost_rob'] < df_wins_t2['cost_det']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = sns.countplot(data=df_wins,\n",
    "#                  y = 'InstanceName',\n",
    "#                  hue = 'Model_rob')\n",
    "# grouped barplot\n",
    "# g = sns.barplot(x=\"ModelName\", y=\"rob_wins\", hue=\"InstanceName\", data=df_wins_t2, ci=None)\n",
    "g = sns.catplot(y=\"ModelName\", x=\"MaxRobCost_Smaller\",\n",
    "                 col=\"InstanceName\", hue=\"RTCS_Policy\", \n",
    "                 palette=\"pastel\", edgecolor=\".6\", # orient=\"h\", height=1.5, aspect=4, \n",
    "                 data=df_wins_t2, kind=\"bar\", ci=None)\n",
    "g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins_t2.set_index(['InstanceName', 'ModelName', 'RTCS_Policy']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4. RTCS performance map (robust wins)\n",
    "\n",
    "Number of scenarios where Robust RTCS obtained smaller cost, when compared to the Deterministic RTCS, when simulating the same scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenario = df.drop(columns=['t', 'd', 'OptTimeSpent', 'ObjValue'])\n",
    "df_scenario['ModelName'] = df_scenario['Model']\n",
    "df_scenario.loc[(df_scenario['Model'] == 'robust-budget'), 'ModelName'] = df_scenario.loc[(df_scenario['Model'] == 'robust-budget'), 'Model'] + '-'\\\n",
    "    + df_scenario.loc[(df_scenario['Model'] == 'robust-budget'), 'GammaPerc'].astype(str)\n",
    "df_scenario = df_scenario.groupby(by=['InstanceName', 'Model', 'ModelName', 'RTCS_Policy', 'ScenarioId']).sum()\\\n",
    "    .drop(columns=['gap', 'RealProcTime', 'GammaPerc', 'Gamma']).reset_index()\n",
    "\n",
    "# simulation cost of the deterministic model, per scenario\n",
    "df_cost_det = df_scenario[(df_scenario['Model'] == 'deterministic')]\n",
    "# simulation cost of the box model, per scenario\n",
    "df_cost_box = df_scenario[(df_scenario['Model'] == 'robust-box')]\n",
    "# simulation cost of the budget model, per scenario\n",
    "df_cost_bud = df_scenario[(df_scenario['Model'] == 'robust-budget')]\n",
    "\n",
    "df_t3 = pd.concat([df_cost_det, df_cost_box, df_cost_bud])\n",
    "df_cheapest_policy_per_scenario = df_t3.drop(columns=['e_td_x', 'e_td_y', 'Reoptimize']).groupby(by=['InstanceName', 'ScenarioId']).min()\n",
    "df_cheapest_policy_per_scenario.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"ModelName\", \n",
    "                 col=\"InstanceName\", hue=\"RTCS_Policy\",\n",
    "                 data=df_cheapest_policy_per_scenario.reset_index(), kind=\"count\", ci=None)\n",
    "g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_scenario.reset_index().drop(columns=['e_td_x', 'e_td_y'])\n",
    "df_target = df_target[(df_target['Model'] == 'robust-budget') | (df_target['Model'] == 'robust-box')]\n",
    "df_det = df_scenario.reset_index().drop(columns=['e_td_x', 'e_td_y', 'ModelName'])\n",
    "df_det = df_det[df_det['Model'] == 'deterministic']\n",
    "df_wins_t3 = df_target.merge(df_det, on=['InstanceName', 'RTCS_Policy', 'ScenarioId'], suffixes=('_target', '_det'))\\\n",
    "    .drop(columns=['Model_det', 'Model_target'])\n",
    "df_wins_t3['Cost_Smaller'] = (df_wins_t3['cost_target'] <= df_wins_t3['cost_det']).astype(int)\n",
    "df_wins_t3['Perc_Cost_Diff'] = np.round(100 * (df_wins_t3['cost_target'] - df_wins_t3['cost_det']) / df_wins_t3['cost_det'], 2)\n",
    "df_wins_t3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins_t3_grouped = df_wins_t3.groupby(by=['InstanceName', 'ModelName', 'RTCS_Policy']).sum()  # 'ForecastType'\n",
    "df_wins_t3_grouped_perc = df_wins_t3_grouped.reset_index().merge(df_num_scenarios_per_instance, on=['InstanceName', 'ModelName', 'RTCS_Policy'])\n",
    "df_wins_t3_grouped_perc['Cost_Smaller_Perc'] = np.round((100 * df_wins_t3_grouped_perc['Cost_Smaller']) / df_wins_t3_grouped_perc['ScenarioCount'], 0).astype(int)\n",
    "df_wins_t3_grouped_perc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"ModelName\", y=\"Cost_Smaller_Perc\",\n",
    "                 col=\"InstanceName\", hue=\"RTCS_Policy\",\n",
    "                 data=df_wins_t3_grouped_perc.reset_index(), kind=\"bar\", ci=None, orient='v')\n",
    "g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 5. Average % difference in solution cost (det vs. others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins_t4_grouped = df_wins_t3.groupby(by=['InstanceName', 'ModelName', 'RTCS_Policy']).agg({'Perc_Cost_Diff' : ['mean', 'std']})\n",
    "df_wins_t4_grouped.columns = ['_'.join(t) for t in df_wins_t4_grouped.columns]\n",
    "df_wins_t4_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"ModelName\", y=\"Perc_Cost_Diff_mean\",\n",
    "                 col=\"InstanceName\", hue=\"RTCS_Policy\",\n",
    "                 data=df_wins_t4_grouped.reset_index(), kind=\"bar\", ci=None, orient='v')\n",
    "g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 6. Cheapest RTCS Strategy, per instance, model type and Gamma parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_key = ['InstanceName', 'Model', 'GammaPerc', 'RTCS_Policy', 'ScenarioId']\n",
    "df_group = df.drop(columns=['t', 'd', 'OptTimeSpent', 'ObjValue']).groupby(by=group_key).sum()\\\n",
    "    .drop(columns=['gap', 'RealProcTime'])\n",
    "display(df_group.head())\n",
    "# Find the cheapest strategy for each model type\n",
    "df_cheapest = df_group.groupby(by=['InstanceName', 'Model', 'GammaPerc', 'ScenarioId']).min().drop(columns=['e_td_x', 'Reoptimize'])\n",
    "df_cheapest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of scenarios per test\n",
    "df_num_scenarios = df_cheapest.reset_index().groupby(by=['InstanceName', 'Model', 'GammaPerc']).count()[['ScenarioId']]\n",
    "df_num_scenarios = df_num_scenarios.reset_index().rename(columns={\"ScenarioId\": \"num_scenarios\"})\n",
    "#df_num_scenarios.to_excel(os.path.join(reportfolder_table, 'japan-num_scenarios-per-instance.xlsx'))\n",
    "df_num_scenarios.to_csv(os.path.join(reportfolder_table, 'japan-num_scenarios-per-instance.csv'))\n",
    "df_num_scenarios.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario-wise cheapest strategy comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_cheapest.reset_index()\n",
    "# Get the information about the cheapest strategies, per instance, model, gamma and scenario\n",
    "df_wins_cheapest = df_target.merge(df_group.reset_index(), on=['InstanceName', 'Model', 'GammaPerc', 'ScenarioId'], suffixes=('_cheapest', ''))\n",
    "df_wins_cheapest['wins'] = (np.abs((df_wins_cheapest['cost'] - df_wins_cheapest['cost_cheapest'])/df_wins_cheapest['cost_cheapest']) < 0.001).astype(int)\n",
    "df_wins_per_instance_model_gamma_policy = df_wins_cheapest.groupby(by=['InstanceName', 'Model', 'GammaPerc', 'RTCS_Policy']).sum()[['wins']]\n",
    "df_wins_per_instance_model_gamma_policy.rename(columns={\"wins\": \"scenario_wins\"}, inplace=True)\n",
    "#df_wins_per_instance_model_gamma_policy.reset_index().to_excel(os.path.join(reportfolder_table, 'japan-df_wins_per_instance_model_gamma_policy.xlsx'))\n",
    "df_wins_per_instance_model_gamma_policy.reset_index().to_csv(os.path.join(reportfolder_table, 'japan-df_wins_per_instance_model_gamma_policy.csv'))\n",
    "display(df_wins_per_instance_model_gamma_policy)\n",
    "df_perc_wins_per_instance_model_gamma_policy = df_wins_per_instance_model_gamma_policy.reset_index().merge(df_num_scenarios, on=['InstanceName', 'Model', 'GammaPerc'])\n",
    "df_perc_wins_per_instance_model_gamma_policy['perc_scenario_wins'] = 100.0 * df_perc_wins_per_instance_model_gamma_policy['scenario_wins'] / df_perc_wins_per_instance_model_gamma_policy['num_scenarios']\n",
    "#df_perc_wins_per_instance_model_gamma_policy.to_excel(os.path.join(reportfolder_table, 'japan-df_perc_wins_per_instance_model_gamma_policy.xlsx'))\n",
    "df_perc_wins_per_instance_model_gamma_policy.to_csv(os.path.join(reportfolder_table, 'japan-df_perc_wins_per_instance_model_gamma_policy.csv'))\n",
    "df_perc_wins_per_instance_model_gamma_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins_grouped = df_wins_cheapest.groupby(by=['InstanceName', 'Model_target', 'GammaPerc_target']).sum().drop(columns=['ScenarioId'])\n",
    "df_wins_grouped['rob_wins_%'] = np.round(100 * df_wins_grouped['rob_wins'] / df_wins_grouped['#scenarios'], 2)\n",
    "#df_wins_grouped['det_wins_%'] = np.round(100 * df_wins_grouped['det_wins'] / df_wins_grouped['#scenarios'], 2)\n",
    "df_wins_grouped = df_wins_grouped.merge(df_num_scenarios_per_instance, left_on=['InstanceName', 'Model_target', 'GammaPerc_target'],\n",
    "                                        right_on=['InstanceName', 'Model', 'GammaPerc'])\n",
    "df_wins_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"ModelName\", y=\"rob_wins_%\",\n",
    "                 col=\"InstanceName\", hue=\"RTCS_Policy\",\n",
    "                 data=df_wins_grouped.reset_index(), kind=\"bar\", ci=None, orient='v')\n",
    "g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating VaR and CVaR\n",
    "\n",
    "Reference: https://quantdare.com/value-at-risk-or-expected-shortfall/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenario_cost = df.groupby(by=['InstanceName', 'Model', 'ModelName', 'GammaPerc', 'RTCS_Policy', 'ScenarioId'])\\\n",
    "    .agg({'cost' : sum})\n",
    "df_scenario_cost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cost Avg...')\n",
    "pd.pivot_table(df_scenario_cost.reset_index(), values='cost', index=['InstanceName', 'RTCS_Policy'],\n",
    "                    columns=['ModelName'], aggfunc=np.mean).reindex(['deterministic-0','deterministic-50','deterministic-100','robust-budget-0', 'robust-budget-20','robust-budget-40',\n",
    "                                                                                    'robust-budget-60', 'robust-budget-80', 'robust-budget-100', 'robust-box'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VaR: 95% certain that losses will not exceed the value of...')\n",
    "pd.pivot_table(df_scenario_cost.reset_index(), values='cost', index=['InstanceName', 'RTCS_Policy'],\n",
    "                    columns=['ModelName'], aggfunc=value_at_risk).reindex(['deterministic-0','deterministic-50','deterministic-100',\n",
    "                                                                           'robust-budget-0', 'robust-budget-20','robust-budget-40',\n",
    "                                                                                    'robust-budget-60', 'robust-budget-80', 'robust-budget-100', 'robust-box'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CVaR: estimate of expected losses sustained in the worst 1 - x% of scenarios')\n",
    "df_cvar = pd.pivot_table(df_scenario_cost.reset_index(), values='cost', index=['InstanceName', 'RTCS_Policy'],\n",
    "                    columns=['ModelName'], aggfunc=expected_shortfall).reindex(['deterministic-0','deterministic-50','deterministic-100',\n",
    "                                                                                'robust-budget-0', 'robust-budget-20','robust-budget-40',\n",
    "                                                                                    'robust-budget-60', 'robust-budget-80', 'robust-budget-100', 'robust-box'], axis=1)\n",
    "df_cvar\n",
    "#df_cvar.style.format(precision=0, na_rep='MISSING', thousands=\" \",\n",
    "#               formatter={('Decision Tree', 'Tumour'): \"{:.2f}\",\n",
    "#                           ('Regression', 'Non-Tumour'): lambda x: \"$ {:,.1f}\".format(x*-1e6)\n",
    "#                          })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Incluir tabela com valor esperado, SD, VaR 95% e CVaR 95% para cada modelo e estratgia acima."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Getting VaR using value_at_risk function\n",
    "var = value_at_risk(ticker_returns)\n",
    "\n",
    "# Getting ES (CVaR) using expected_shortfall function\n",
    "es = expected_shortfall(ticker_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure. Split violin plot with the costs of each scenario, comparing Rob x Det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box_vs_det = df_scenario [(df_scenario['ModelName'] == 'robust-budget-60') | (df_scenario['ModelName'] == 'deterministic')]\n",
    "df_box_vs_det_1 = df_box_vs_det[(df_box_vs_det['InstanceName'] == 'A_instance2_1000s_skewed-left')]\n",
    "df_box_vs_det['ModelName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "plot4 = sns.catplot(x=\"RTCS_Policy\", y=\"cost\", hue=\"ModelName\",\n",
    "            kind=\"violin\", split=True,\n",
    "            palette=\"pastel\", data=df_box_vs_det_1)\n",
    "plot4.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a4_dims = (11.7, 8.27)\n",
    "#fig, ax = plt.subplots(figsize=a4_dims)\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.catplot(x=\"cost\", y=\"RTCS_Policy\", hue=\"ModelName\", row=\"InstanceName\", \n",
    "            kind=\"violin\", bw=.15, cut=0, \n",
    "            data=df_scenario,\n",
    "            height=25, # make the plot 15 units high\n",
    "            aspect=0.5) # height should be 2 times width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a4_dims = (11.7, 8.27)\n",
    "#fig, ax = plt.subplots(figsize=a4_dims)\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.catplot(x=\"cost\", y=\"RTCS_Policy\", hue=\"ModelName\", \n",
    "            kind=\"violin\", bw=.15, cut=0, \n",
    "            data=df_scenario[(df_scenario['InstanceName'] == 'spring')],\n",
    "            height=25, # make the plot 15 units high\n",
    "            aspect=0.5) # height should be 2 times width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Fazer um kde distribution plot dos custos do RTCS obtidos nas simulacoes: robusto-gamma vs. deterministico\n",
    "\n",
    "### TODO Fazer uma tabela com as medidas estatisticas (para cada distribuicao usada) de cada simulacao, incluindo valor esperado, SD, percentis 95, 99 e valor maximo observado empiricamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=['InstanceName', 'ModelName', 'RTCS_Policy', 'GammaPerc', 'ScenarioId', 't']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_folder in experiment_folder_list:\n",
    "    for instance_group in instance_group_list:\n",
    "        instance_list = get_instance_list(project_folder, antoine_instances_folder, toy_instances_folder, instance_group)\n",
    "        print(instance_group, instance_list)\n",
    "        for model in simulated_model_list:\n",
    "            for forecast_type in forecast_type_list:\n",
    "                print(model, forecast_type)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "        result_path = create_full_dir(normpath(experiment_folder), [\"output\", \"simulation\", \"zip\", instance_name])\n",
    "        scenario_subpath = create_trace_scenario_filename(\n",
    "            model, Gamma_perc, test_name, instance_name, sim_strategy, model_policy, reoptimize, scenario_id)\n",
    "        result_file_base = joinpath(normpath(result_path), scenario_subpath)\n",
    "        output_file_trace_arrow = result_file_base * \".arrow\"\n",
    "        output_file_var_arrow = result_file_base * \"_var.arrow\"\n",
    "    \n",
    "        result_file_zip = result_file_base * \".zip\"\n",
    "        move_files_to_zip_archive(output_file_zip, [output_file_log, output_file_df, output_file_var_arrow, output_file_trace_arrow], general_logger)\n",
    "        trace_df = Arrow.read(output_file_trace_arrow; compress=:lz4)\n",
    "        var_df = Arrow.read(output_file_var_arrow; compress=:lz4)\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-rccp_cronos] *",
   "language": "python",
   "name": "conda-env-.conda-rccp_cronos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
